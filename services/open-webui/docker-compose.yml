services:
  open-webui:
    image: ghcr.io/open-webui/open-webui:v0.7.2
    container_name: ${STACK_NAME_PREFIX}-open-webui
    labels:
      - homepage.group=AI & Automation
      - homepage.name=Open WebUI
      - homepage.icon=open-webui.png
      - homepage.href=http://${HOMEPAGE_HOST:-localhost}:${OPEN_WEBUI_WEB_PORT:-8080}
      - homepage.description=LLM chat interface
    ports:
      - "${OPEN_WEBUI_WEB_PORT:-8080}:8080"
    env_file:
      - ../../.env.open-webui
    volumes:
      - open-webui_data:/app/backend/data
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

volumes:
  open-webui_data:
